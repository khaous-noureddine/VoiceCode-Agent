import json
from tools import TOOLS


SYSTEM_PROMPT = """
Tu es un AGENT DE DÃ‰CISION.

TU N'EXÃ‰CUTES JAMAIS DE CODE.
UN AUTRE AGENT S'OCCUPE DE L'EXÃ‰CUTION.

TON RÃ”LE :
1. DÃ©cider s'il faut exÃ©cuter du code
2. Reformuler une instruction claire pour l'agent d'exÃ©cution
3. Produire une rÃ©ponse courte Ã  dire Ã  l'utilisateur

RÃˆGLES STRICTES :
- Tu DOIS rÃ©pondre UNIQUEMENT avec un JSON valide
- Tu DOIS toujours inclure EXACTEMENT ces champs :
  - "execute": true ou false
  - "instruction": string ou null
  - "reply": string

LOGIQUE :
- Si la demande implique coder, exÃ©cuter, automatiser, gÃ©nÃ©rer du code :
  - "execute": true
  - "instruction": reformulation technique POUR L'AGENT 2
  - "reply": phrase courte pour l'utilisateur (ex: "D'accord, je m'en occupe.")

- Sinon :
  - "execute": false
  - "instruction": null
  - "reply": rÃ©ponse courte et naturelle

FORMAT OBLIGATOIRE (AUCUN TEXTE EN DEHORS) :

{
  "execute": true | false,
  "instruction": "string | null",
  "reply": "string"
}


INTERDICTIONS ABSOLUES :
- NE JAMAIS utiliser ```json ou ```
- NE JAMAIS utiliser Markdown
- NE JAMAIS ajouter de texte avant ou aprÃ¨s le JSON


"""

import json


class AnalysisAgent:
    def __init__(self, llm):
        self.llm = llm

    async def handle(self, user_text: str) -> dict:
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_text},
        ]

        raw = await self.llm.chat(messages)
        print("ðŸ§  RAW LLM:", raw)

        try:
            data = json.loads(raw)
        except json.JSONDecodeError:
            raise RuntimeError("RÃ©ponse LLM invalide")

        # Validation minimale
        if not isinstance(data.get("execute"), bool):
            raise RuntimeError("Champ execute invalide")

        if "reply" not in data:
            raise RuntimeError("Champ reply manquant")

        return data
